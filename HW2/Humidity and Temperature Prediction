import argparse
import numpy as np
import os
import pandas as pd
import tensorflow as tf
import tensorflow.lite as tflite
from tensorflow import keras
import zlib
from platform import python_version
import tensorflow_model_optimization as tfmot   

print(f"Python version used to excute the code is {python_version()}")



zip_path = tf.keras.utils.get_file(
    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',
    fname='jena_climate_2009_2016.csv.zip',
    extract=True,
    cache_dir='.', cache_subdir='data')
csv_path, _ = os.path.splitext(zip_path)
df = pd.read_csv(csv_path)

column_indices = [2, 5]
columns = df.columns[column_indices]
data = df[columns].values.astype(np.float32)

n = len(data)
train_data = data[0:int(n*0.7)]
val_data = data[int(n*0.7):int(n*0.9)]
test_data = data[int(n*0.9):]

mean = train_data.mean(axis=0)
std = train_data.std(axis=0)
    
######################################################### Creating the WindowGenerator Class #########################################################

class WindowGenerator:
    def __init__(self, input_width, output_steps, mean, std):
        self.input_width = input_width
        self.output_steps = output_steps
        self.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])
        self.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])


    def split_window(self, features):
        inputs = features[:, :self.input_width, :]        # for example if total window size = 9 input =  [:,:6 ,:] --> output [:,-3: , ] outpu_tstep = 3 
        labels = features[:, -self.output_steps :, :]

        inputs.set_shape([None, self.input_width, 2])
        labels.set_shape([None, self.output_steps,2])

        return inputs, labels

    def normalize(self, features):                         # apply normalization
        features = (features - self.mean) / (self.std + 1.e-6)

        return features

    def preprocess(self, features):                         # preprocessing pipleline 
        inputs, labels = self.split_window(features)
        inputs = self.normalize(inputs)

        return inputs, labels

    def make_dataset(self, data, train):                    # make tensorflow data set of timeseries  
        ds = tf.keras.preprocessing.timeseries_dataset_from_array(
                data=data,
                targets=None,
                sequence_length = input_width + self.output_steps,                       #### the length of the window is dependant on both the input & output widht
                sequence_stride = 1,                                                     # silde the window by one in each iteration 
                batch_size = 32)
        ds = ds.map(self.preprocess)
        ds = ds.cache()                                                           # useful to avoid repeating the preprocessing functions everytime (speed up the pipeline)
        if train is True:
            ds = ds.shuffle(100, reshuffle_each_iteration=True)                   # we will shuffle the data before training 

        return ds



generator = WindowGenerator(input_width, output_steps, mean, std)
train_ds = generator.make_dataset(train_data, True)
val_ds = generator.make_dataset(val_data, False)
test_ds = generator.make_dataset(test_data, False)

######################################################### defining the Metric --> MultiOutputMAE class ######################################################### 

class MultiOutputMAE(tf.keras.metrics.Metric):
    def __init__(self, name='mean_absolute_error', **kwargs):
        super().__init__(name=name, **kwargs)
        self.total = self.add_weight('total', initializer='zeros', shape=(2,))
        self.count = self.add_weight('count', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        error = tf.abs(y_pred- y_true)     
        error = tf.reduce_mean(error, axis=[0,1])  # compute the mean for all samples in the batch for each feature (temp , hum) ==> output shape = (2,)
        self.total.assign_add(error)
        self.count.assign_add(1.)

        return

    def reset_states(self):
        self.count.assign(tf.zeros_like(self.count))
        self.total.assign(tf.zeros_like(self.total))

    def result(self):
        result = tf.math.divide_no_nan(self.total, self.count)

        return result
