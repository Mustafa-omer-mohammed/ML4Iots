import argparse
import numpy as np
import os
import pandas as pd
import tensorflow as tf
import tensorflow.lite as tflite
from tensorflow import keras
import zlib
from platform import python_version
import tensorflow_model_optimization as tfmot   

print(f"Python version used to excute the code is {python_version()}")



zip_path = tf.keras.utils.get_file(
    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',
    fname='jena_climate_2009_2016.csv.zip',
    extract=True,
    cache_dir='.', cache_subdir='data')
csv_path, _ = os.path.splitext(zip_path)
df = pd.read_csv(csv_path)

column_indices = [2, 5]
columns = df.columns[column_indices]
data = df[columns].values.astype(np.float32)

n = len(data)
train_data = data[0:int(n*0.7)]
val_data = data[int(n*0.7):int(n*0.9)]
test_data = data[int(n*0.9):]

mean = train_data.mean(axis=0)
std = train_data.std(axis=0)
    
######################################################### Creating the WindowGenerator Class #########################################################

class WindowGenerator:
    def __init__(self, input_width, output_steps, mean, std):
        self.input_width = input_width
        self.output_steps = output_steps
        self.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])
        self.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])


    def split_window(self, features):
        inputs = features[:, :self.input_width, :]        # for example if total window size = 9 input =  [:,:6 ,:] --> output [:,-3: , ] outpu_tstep = 3 
        labels = features[:, -self.output_steps :, :]

        inputs.set_shape([None, self.input_width, 2])
        labels.set_shape([None, self.output_steps,2])

        return inputs, labels

    def normalize(self, features):                         # apply normalization
        features = (features - self.mean) / (self.std + 1.e-6)

        return features

    def preprocess(self, features):                         # preprocessing pipleline 
        inputs, labels = self.split_window(features)
        inputs = self.normalize(inputs)

        return inputs, labels

    def make_dataset(self, data, train):                    # make tensorflow data set of timeseries  
        ds = tf.keras.preprocessing.timeseries_dataset_from_array(
                data=data,
                targets=None,
                sequence_length = input_width + self.output_steps,                       #### the length of the window is dependant on both the input & output widht
                sequence_stride = 1,                                                     # silde the window by one in each iteration 
                batch_size = 32)
        ds = ds.map(self.preprocess)
        ds = ds.cache()                                                           # useful to avoid repeating the preprocessing functions everytime (speed up the pipeline)
        if train is True:
            ds = ds.shuffle(100, reshuffle_each_iteration=True)                   # we will shuffle the data before training 

        return ds



generator = WindowGenerator(input_width, output_steps, mean, std)
train_ds = generator.make_dataset(train_data, True)
val_ds = generator.make_dataset(val_data, False)
test_ds = generator.make_dataset(test_data, False)

######################################################### defining the Metric --> MultiOutputMAE class ######################################################### 

class MultiOutputMAE(tf.keras.metrics.Metric):
    def __init__(self, name='mean_absolute_error', **kwargs):
        super().__init__(name=name, **kwargs)
        self.total = self.add_weight('total', initializer='zeros', shape=(2,))
        self.count = self.add_weight('count', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        error = tf.abs(y_pred- y_true)     
        error = tf.reduce_mean(error, axis=[0,1])  # compute the mean for all samples in the batch for each feature (temp , hum) ==> output shape = (2,)
        self.total.assign_add(error)
        self.count.assign_add(1.)

        return

    def reset_states(self):
        self.count.assign(tf.zeros_like(self.count))
        self.total.assign(tf.zeros_like(self.total))

    def result(self):
        result = tf.math.divide_no_nan(self.total, self.count)

        return result
######################################################### Parameters to change :

alpha = 0.03           # the width multiplier 


model_version = f"_V_{version}_alpha={alpha} )"

mymodel = 'mlp'+ model_version                                  # change the model used ['mlp' , 'cnn']
chk_path = f'./callback_{mymodel}_chkp/{mymodel}_chkp_best'     # path for saving the best model 
TFLITE = f'Group26_th_{version}.tflite'                                    # path for saving the best model after converted to TF.lite model 

#################################### Build models with Structured Pruning via width Multiplier #####################################################
def bulid_models_Structured (alpha = alpha , version = version , input_width = input_width ,output_steps = output_steps ,model_version = model_version  ) :
    mlp = tf.keras.Sequential([
            tf.keras.layers.Flatten(input_shape = (input_width,2) , name='Flatten'),
            tf.keras.layers.Dense(int(128 *alpha), activation='relu' , name='Dense1'),
            tf.keras.layers.Dense(int(128 *alpha), activation='relu' , name='Dense2'),
            tf.keras.layers.Dense(units = 2*output_steps , name='Output_layes'), 
            tf.keras.layers.Reshape([output_steps, 2])
        ])

    ############################################################################
    cnn = tf.keras.Sequential([
            tf.keras.layers.Conv1D(input_shape = (input_width,2) , filters=int(64 *alpha), kernel_size=3, activation='relu'),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(units=int(64 *alpha), activation='relu'),
            tf.keras.layers.Dense(units=2*output_steps), 
            tf.keras.layers.Reshape([output_steps, 2])
        ])

  

    MODELS = {'mlp'+ model_version: mlp, 'cnn'+ model_version: cnn }
    return MODELS 


 


MODELS = bulid_models_Structured()


######################################################### Define losses & Optimizer & metrics #########################################################

######################################################### Function to initiate and compile the model #########################################################
def get_model(model = mymodel ):
    model = MODELS[model]
    loss =   tf.keras.losses.MeanSquaredError()                       #tf.keras.losses.MeanSquaredError()
    optimizer = tf.keras.optimizers.Adam()
    metrics = [MultiOutputMAE()]

    # Training and optimizing

    model.compile(loss = loss, optimizer = optimizer, metrics = metrics)
    
    return model
######################################################### define call backs  #########################################################

############## Create custom call-back TEMP_HUM_VAL  callback to print the MAE for Temperature and humidity in a more interpretable format during the training.
class TEMP_HUM_VAL(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs):
        hum = logs["val_mean_absolute_error"][1]
        temp = logs["val_mean_absolute_error"][0]
        MAE = logs["val_mean_absolute_error"]
        print(f"\n Temp MAE = {temp:.3f}, Hum MAE = {hum:.3f}    ")
        # return temp , hum


mycallback = TEMP_HUM_VAL()

############## Create checkpoint callback to save the best model 
cp_callback = keras.callbacks.ModelCheckpoint(
    f'./callback_{mymodel}_chkp/{mymodel}_chkp_best',
    # './callback_test_chkp/chkp_best',
    monitor='val_loss',
    verbose=0, 
    save_best_only=True,
    save_weights_only=False,
    mode='auto',
    save_freq='epoch')
    
######################################################### Train with Structured Pruning #########################################################
model = get_model(mymodel)
history = model.fit(train_ds, epochs=30,   validation_data=val_ds,callbacks=[mycallback ,cp_callback ])
######################################################### Print Model Summary #########################################################
print(model.summary())

######################################################### Function to Evaluate the best Model and Convert to Tf lite  #########################################################
def S_pruning_Model_evaluate_and_compress_to_TFlite( tflite_model_dir =  TFLITE , chk_path = chk_path , model_name = mymodel):
    if not os.path.exists('./models'):
        os.makedirs('./models')
    model = tf.keras.models.load_model(filepath = chk_path , custom_objects={'MultiOutputMAE':MultiOutputMAE})

    run_model = tf.function(lambda x: model(x))
    # input_shape = model.inputs[0].shape.as_list()
    # input_shape[0] = batch_size
    # func = tf.function(model).get_concrete_function(
    # tf.TensorSpec(input_shape, model.inputs[0].dtype))
    concrete_func = run_model.get_concrete_function(tf.TensorSpec([1, 6, 2], tf.float32))
    saving_path = os.path.join('.','models', model_name)
    model.save(saving_path ,signatures=concrete_func )

    best_model = tf.keras.models.load_model(filepath = saving_path , custom_objects={'MultiOutputMAE':MultiOutputMAE})
    loss, error = best_model.evaluate(test_ds)
    print( "*" *50,"\n",f'Evaluating best model before convertion to TF lite ')
    print( "*" *50,"\n",f'Temp mae = {error[0]:.3f}: , HUM mae = {error[1]:.3f} ')

    return saving_path
    
 
######################################################### Function to Apply Quantization  #########################################################
def apply_Quantization(tflite_model_dir =  TFLITE ,  PQT = False , WAPQT = False , saving_path = None ): 
 
    converter = tf.lite.TFLiteConverter.from_saved_model(saving_path)
    # Apply weight only Post Training quantization  
    if PQT == True :
        tflite_model_dir = f"{tflite_model_dir}"        
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        tflite_model = converter.convert()
    # Apply weight + Activation Post Training quantization 
    if WAPQT == True :
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.representative_dataset = representative_dataset_gen
        tflite_model = converter.convert()
        
        tflite_model_dir = f"{tflite_model_dir}"
      
    # Write the model in binary formate and save it 
    with open(tflite_model_dir, 'wb') as fp:
        fp.write(tflite_model)
    Compressed =  f"{tflite_model_dir}.zlib"
    with open(Compressed, 'wb') as fp:
        tflite_compressed = zlib.compress(tflite_model)
        fp.write(tflite_compressed)
    print("*" *50,"\n",f"the Quantized TF lite model is saved successfuly to {tflite_model_dir}")
    return Compressed , tflite_model_dir 
######################################################### Function for weight and activations quantization to create Representative data #########################################################
def representative_dataset_gen():
    for x, _ in train_ds.take(1000):
        yield [x]
