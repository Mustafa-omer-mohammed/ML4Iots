{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e854e63-b2d1-4066-9018-5e471fbdcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.lite as tflite\n",
    "from tensorflow import keras\n",
    "import zlib\n",
    "\n",
    "import tensorflow_model_optimization as tfmot   \n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--model', type=str, required=True, help='model name')\n",
    "# parser.add_argument('--labels', type=int, required=True, help='model output')\n",
    "# args = parser.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb58f23-5c70-495d-9a19-2d746ca6ecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.11\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2630fca0-5061-4117-a6d9-1a36ca4a4e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True,\n",
    "    cache_dir='.', cache_subdir='data')\n",
    "csv_path, _ = os.path.splitext(zip_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "column_indices = [2, 5]\n",
    "columns = df.columns[column_indices]\n",
    "data = df[columns].values.astype(np.float32)\n",
    "\n",
    "n = len(data)\n",
    "train_data = data[0:int(n*0.7)]\n",
    "val_data = data[int(n*0.7):int(n*0.9)]\n",
    "test_data = data[int(n*0.9):]\n",
    "\n",
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "\n",
    "print (mean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2997a3e-9d6e-49c8-bb17-6469e0602568",
   "metadata": {},
   "source": [
    "# WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f0113e-bd14-4dd6-9872-c045adf11913",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 6\n",
    "version = \"a\"                     ####### Remove this later\n",
    "if version == \"a\" :               ####### Remember this is the argparse Arument --version \n",
    "    output_steps = 3\n",
    "if version == \"b\" :\n",
    "    output_steps = 9\n",
    "\n",
    "\n",
    "class WindowGenerator:\n",
    "    def __init__(self, input_width, output_steps, mean, std):\n",
    "        self.input_width = input_width\n",
    "        self.output_steps = output_steps\n",
    "        self.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])\n",
    "        self.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])\n",
    "\n",
    "\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, :self.input_width, :]        # for example if total window size = 9 input =  [:,:6 ,:] --> output [:,-3: , ] outpu_tstep = 3 \n",
    "        labels = features[:, -self.output_steps :, :]\n",
    "\n",
    "        inputs.set_shape([None, self.input_width, 2])\n",
    "        labels.set_shape([None, self.output_steps,2])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def normalize(self, features):\n",
    "        features = (features - self.mean) / (self.std + 1.e-6)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def preprocess(self, features):\n",
    "        inputs, labels = self.split_window(features)\n",
    "        inputs = self.normalize(inputs)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self, data, train):\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "                data=data,\n",
    "                targets=None,\n",
    "                sequence_length = input_width + self.output_steps,                       #### this change because now the total depends on the output widht\n",
    "                sequence_stride = 1,\n",
    "                batch_size = 32)\n",
    "        ds = ds.map(self.preprocess)\n",
    "        ds = ds.cache()\n",
    "        if train is True:\n",
    "            ds = ds.shuffle(100, reshuffle_each_iteration=True)\n",
    "\n",
    "        return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "669e1a5f-8f69-45c8-8113-a5f9d2c58ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = np.arange(18)\n",
    "# window = window.reshape(9,2)\n",
    "# print(len(window))\n",
    "# print(window)\n",
    "# print(window[:6].shape)\n",
    "# print(window[-3:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0494564-1658-4fef-954a-c68d8e43aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = WindowGenerator(input_width, output_steps, mean, std)\n",
    "train_ds = generator.make_dataset(train_data, True)\n",
    "val_ds = generator.make_dataset(val_data, False)\n",
    "test_ds = generator.make_dataset(test_data, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df990243-6f6c-423c-82ac-48394aaba1e0",
   "metadata": {},
   "source": [
    "# checking the shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43459a86-1f13-437e-97cb-d69cf31dd1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape before split (420551, 2)\n",
      "train_data (294385, 2)\n",
      "val_data (84110, 2)\n",
      "test_data (42056, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"data shape before split {data.shape}\")\n",
    "\n",
    "print(f\"train_data {train_data.shape}\")\n",
    "\n",
    "print(f\"val_data {val_data.shape}\")\n",
    "\n",
    "print(f\"test_data {test_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7674be-c965-434b-b755-6b580a570ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb242899-5272-42fa-8bbd-8a7549fc3e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.7288457  0.6097644], shape=(2,), dtype=float32)\n",
      "tf.Tensor([ 2.58 86.2 ], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inp , label = next(it)\n",
    "print(inp[0,0,:])\n",
    "print(label[0,0,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fec2d-cfbf-4d4b-83d1-c79d9990dfc1",
   "metadata": {},
   "source": [
    "# MultiOutputMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04dbeda9-86ed-4738-8ef3-00e95ef20e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exercise 1.7\n",
    "class MultiOutputMAE(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='mean_absolute_error', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.total = self.add_weight('total', initializer='zeros', shape=(2,))\n",
    "        self.count = self.add_weight('count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        error = tf.abs(y_pred- y_true)     \n",
    "        error = tf.reduce_mean(error, axis=[0,1])  # compute the mean for all samples in the batch for each feature (temp , hum) ==> output shape = (2,)\n",
    "        self.total.assign_add(error)\n",
    "        self.count.assign_add(1.)\n",
    "\n",
    "        return\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.count.assign(tf.zeros_like(self.count))\n",
    "        self.total.assign(tf.zeros_like(self.total))\n",
    "\n",
    "    def result(self):\n",
    "        result = tf.math.divide_no_nan(self.total, self.count)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf89bc-9183-41d8-8b5a-5cbd15171774",
   "metadata": {},
   "source": [
    "# building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ec65fb-5e88-4598-b606-838136be3a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_V( a_alpha=0.03 )\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.03\n",
    "# alpha = 1\n",
    "sparsity = 0.9\n",
    "Structured = True\n",
    "if Structured == True :\n",
    "    model_version = f\"_V( {version}_alpha={alpha} )\"\n",
    "else :\n",
    "    model_version = f\"_V( {version}_Sparcity ={sparsity} )\"\n",
    "mymodel = 'mlp'+ model_version\n",
    "chk_path = f'./callback_{mymodel}_chkp/{mymodel}_chkp_best'     # path for saving the best model \n",
    "TFLITE = mymodel + \".tflite\"                                    # path for saving the best model after converted to TF.lite model \n",
    "\n",
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a7f2c8-643d-4fa1-9d3a-3f6ac383907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Build models with Structured Pruning via width Multiplier #####################################################\n",
    "def bulid_models_Structured (alpha = alpha , version = version , input_width = input_width ,output_steps = output_steps ,model_version = model_version  ) :\n",
    "    mlp = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape = (input_width,2) , name='Flatten'),\n",
    "            tf.keras.layers.Dense(int(128 *alpha), activation='relu' , name='Dense1'),\n",
    "            tf.keras.layers.Dense(int(128 *alpha), activation='relu' , name='Dense2'),\n",
    "            tf.keras.layers.Dense(units = 2*output_steps , name='Output_layes'), \n",
    "            tf.keras.layers.Reshape([output_steps, 2])\n",
    "        ])\n",
    "\n",
    "    ############################################################################\n",
    "    cnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv1D(input_shape = (input_width,2) , filters=int(64 *alpha), kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=int(64 *alpha), activation='relu'),\n",
    "            tf.keras.layers.Dense(units=2*output_steps), \n",
    "            tf.keras.layers.Reshape([output_steps, 2])\n",
    "        ])\n",
    "\n",
    "  \n",
    "\n",
    "    MODELS = {'mlp'+ model_version: mlp, 'cnn'+ model_version: cnn }\n",
    "    return MODELS \n",
    "\n",
    "####################################       Build models with UnStructured Pruning         #####################################################\n",
    "\n",
    "def bulid_models_UnStructured ( version = version , input_width = input_width ,output_steps = output_steps ,model_version = model_version  ) :\n",
    "    mlp = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape = (input_width,2) , name='Flatten'),\n",
    "            tf.keras.layers.Dense(128, activation='relu' , name='Dense1'),\n",
    "            tf.keras.layers.Dense(128, activation='relu' , name='Dense2'),\n",
    "            tf.keras.layers.Dense(units = 2*output_steps , name='Output_layes'), \n",
    "            tf.keras.layers.Reshape([output_steps, 2])\n",
    "        ])\n",
    "\n",
    "    ############################################################################\n",
    "    cnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv1D(input_shape = (input_width,2) , filters=64, kernel_size=3, activation='relu' , name= \"Conv1D-1\"),\n",
    "            tf.keras.layers.Flatten(name='Flatten'),\n",
    "            tf.keras.layers.Dense(units=64, activation='relu', name='Dense-1'),\n",
    "            tf.keras.layers.Dense(units=2*output_steps), \n",
    "            tf.keras.layers.Reshape([output_steps, 2])\n",
    "        ])\n",
    "\n",
    " \n",
    "\n",
    "    MODELS = {'mlp'+ model_version: mlp, 'cnn'+ model_version: cnn }\n",
    "    return MODELS \n",
    "\n",
    "if Structured == True :\n",
    "    MODELS = bulid_models_Structured()\n",
    "else :\n",
    "    MODELS = bulid_models_UnStructured()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ff7847-5c1f-4d91-b905-1df171f6139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pydot\n",
    "# ! pip install pydotplus\n",
    "# ! pip install graphviz\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aa53ad5-a5ef-459f-927d-207af18b47f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mlp_V( a_alpha=0.03 )', 'cnn_V( a_alpha=0.03 )'])\n"
     ]
    }
   ],
   "source": [
    "print(MODELS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81720020-46c5-4fa7-ba23-dcb757909f79",
   "metadata": {},
   "source": [
    "# Define losses & Optimizer & metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6111f00-342d-4f04-8309-5b160a9d7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model = mymodel ):\n",
    "    model = MODELS[model]\n",
    "    loss =   tf.keras.losses.MeanSquaredError()                       #tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    metrics = [MultiOutputMAE()]\n",
    "\n",
    "    # Training and optimizing\n",
    "\n",
    "    model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8629de26-4691-43e6-ae6d-07a1311af0f0",
   "metadata": {},
   "source": [
    "# define call backs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53d09677-3b03-4ad3-ad0a-1565915ebeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TEMP_HUM_VAL  callback to print the MAE for Temperature and humidity in more interpetable format \n",
    "class TEMP_HUM_VAL(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        hum = logs[\"val_mean_absolute_error\"][1]\n",
    "        temp = logs[\"val_mean_absolute_error\"][0]\n",
    "        MAE = logs[\"val_mean_absolute_error\"]\n",
    "        print(f\"\\n Temp MAE = {temp:.3f}, Hum MAE = {hum:.3f}    \")\n",
    "        # return temp , hum\n",
    "\n",
    "\n",
    "mycallback = TEMP_HUM_VAL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc272011-026f-4d88-a371-2e689288906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint callback to save the best model \n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    f'./callback_{mymodel}_chkp/{mymodel}_chkp_best',\n",
    "    # './callback_test_chkp/chkp_best',\n",
    "    monitor='val_loss',\n",
    "    verbose=0, \n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d96e2b24-943a-4fb5-8704-592d6d7d0aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9193/9200 [============================>.] - ETA: 0s - loss: 520.7838 - mean_absolute_error: 12.9874\n",
      " Temp MAE = 9.541, Hum MAE = 2.412    \n",
      "WARNING:tensorflow:From C:\\Users\\musta\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\musta\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 13s 1ms/step - loss: 520.4069 - mean_absolute_error: 12.9801 - val_loss: 68.3634 - val_mean_absolute_error: 5.9766\n",
      "Epoch 2/50\n",
      "9135/9200 [============================>.] - ETA: 0s - loss: 29.3626 - mean_absolute_error: 3.5652\n",
      " Temp MAE = 4.312, Hum MAE = 2.886    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 11s 1ms/step - loss: 29.2187 - mean_absolute_error: 3.5539 - val_loss: 22.9285 - val_mean_absolute_error: 3.5994\n",
      "Epoch 3/50\n",
      "9161/9200 [============================>.] - ETA: 0s - loss: 3.8271 - mean_absolute_error: 1.2104\n",
      " Temp MAE = 0.535, Hum MAE = 1.307    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 11s 1ms/step - loss: 3.8215 - mean_absolute_error: 1.2091 - val_loss: 2.4596 - val_mean_absolute_error: 0.9209\n",
      "Epoch 4/50\n",
      "9177/9200 [============================>.] - ETA: 0s - loss: 2.1079 - mean_absolute_error: 0.8042\n",
      " Temp MAE = 0.347, Hum MAE = 1.160    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 10s 1ms/step - loss: 2.1075 - mean_absolute_error: 0.8042 - val_loss: 2.0066 - val_mean_absolute_error: 0.7535\n",
      "Epoch 5/50\n",
      "9158/9200 [============================>.] - ETA: 0s - loss: 2.0008 - mean_absolute_error: 0.7674\n",
      " Temp MAE = 0.331, Hum MAE = 1.201    \n",
      "9200/9200 [==============================] - 9s 946us/step - loss: 2.0048 - mean_absolute_error: 0.7682 - val_loss: 2.0757 - val_mean_absolute_error: 0.7663\n",
      "Epoch 6/50\n",
      "9130/9200 [============================>.] - ETA: 0s - loss: 1.9653 - mean_absolute_error: 0.7526\n",
      " Temp MAE = 0.337, Hum MAE = 1.157    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 9s 1ms/step - loss: 1.9675 - mean_absolute_error: 0.7536 - val_loss: 1.9692 - val_mean_absolute_error: 0.7470\n",
      "Epoch 7/50\n",
      "9173/9200 [============================>.] - ETA: 0s - loss: 1.9369 - mean_absolute_error: 0.7407\n",
      " Temp MAE = 0.276, Hum MAE = 1.156    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 9s 996us/step - loss: 1.9402 - mean_absolute_error: 0.7414 - val_loss: 1.9470 - val_mean_absolute_error: 0.7159\n",
      "Epoch 8/50\n",
      "9131/9200 [============================>.] - ETA: 0s - loss: 1.9210 - mean_absolute_error: 0.7349- ETA: 0s - loss: 1.8891 - mean_absolute\n",
      " Temp MAE = 0.309, Hum MAE = 1.305    \n",
      "9200/9200 [==============================] - 8s 856us/step - loss: 1.9252 - mean_absolute_error: 0.7358 - val_loss: 2.0540 - val_mean_absolute_error: 0.8069\n",
      "Epoch 9/50\n",
      "9190/9200 [============================>.] - ETA: 0s - loss: 1.9131 - mean_absolute_error: 0.7295\n",
      " Temp MAE = 0.281, Hum MAE = 1.113    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 9s 998us/step - loss: 1.9130 - mean_absolute_error: 0.7296 - val_loss: 1.8648 - val_mean_absolute_error: 0.6972\n",
      "Epoch 10/50\n",
      "9194/9200 [============================>.] - ETA: 0s - loss: 1.9052 - mean_absolute_error: 0.7252\n",
      " Temp MAE = 0.258, Hum MAE = 1.097    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 10s 1ms/step - loss: 1.9053 - mean_absolute_error: 0.7253 - val_loss: 1.8607 - val_mean_absolute_error: 0.6775\n",
      "Epoch 11/50\n",
      "9173/9200 [============================>.] - ETA: 0s - loss: 1.8952 - mean_absolute_error: 0.7203\n",
      " Temp MAE = 0.262, Hum MAE = 1.141    \n",
      "9200/9200 [==============================] - 8s 892us/step - loss: 1.8956 - mean_absolute_error: 0.7206 - val_loss: 1.8764 - val_mean_absolute_error: 0.7015\n",
      "Epoch 12/50\n",
      "9187/9200 [============================>.] - ETA: 0s - loss: 1.8869 - mean_absolute_error: 0.717 - ETA: 0s - loss: 1.8890 - mean_absolute_error: 0.7185\n",
      " Temp MAE = 0.259, Hum MAE = 1.101    \n",
      "9200/9200 [==============================] - 9s 934us/step - loss: 1.8901 - mean_absolute_error: 0.7188 - val_loss: 1.8623 - val_mean_absolute_error: 0.6798\n",
      "Epoch 13/50\n",
      "9171/9200 [============================>.] - ETA: 0s - loss: 1.8887 - mean_absolute_error: 0.7178\n",
      " Temp MAE = 0.262, Hum MAE = 1.100    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 10s 1ms/step - loss: 1.8896 - mean_absolute_error: 0.7180 - val_loss: 1.8403 - val_mean_absolute_error: 0.6811\n",
      "Epoch 14/50\n",
      "9187/9200 [============================>.] - ETA: 0s - loss: 1.8891 - mean_absolute_error: 0.7170\n",
      " Temp MAE = 0.262, Hum MAE = 1.113    \n",
      "9200/9200 [==============================] - 10s 1ms/step - loss: 1.8886 - mean_absolute_error: 0.7170 - val_loss: 1.8655 - val_mean_absolute_error: 0.6875\n",
      "Epoch 15/50\n",
      "9167/9200 [============================>.] - ETA: 0s - loss: 1.8784 - mean_absolute_error: 0.7136- ETA: 0s - loss: 1.8779 - mean_absolute_error: 0.713\n",
      " Temp MAE = 0.299, Hum MAE = 1.341    \n",
      "9200/9200 [==============================] - 9s 1ms/step - loss: 1.8819 - mean_absolute_error: 0.7143 - val_loss: 2.0659 - val_mean_absolute_error: 0.8200\n",
      "Epoch 16/50\n",
      "9124/9200 [============================>.] - ETA: 0s - loss: 1.8814 - mean_absolute_error: 0.7137\n",
      " Temp MAE = 0.258, Hum MAE = 1.128    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 9s 1ms/step - loss: 1.8818 - mean_absolute_error: 0.7143 - val_loss: 1.8385 - val_mean_absolute_error: 0.6927\n",
      "Epoch 17/50\n",
      "9153/9200 [============================>.] - ETA: 0s - loss: 1.8791 - mean_absolute_error: 0.7140\n",
      " Temp MAE = 0.270, Hum MAE = 1.168    \n",
      "9200/9200 [==============================] - 8s 881us/step - loss: 1.8840 - mean_absolute_error: 0.7151 - val_loss: 1.8875 - val_mean_absolute_error: 0.7190\n",
      "Epoch 18/50\n",
      "9152/9200 [============================>.] - ETA: 0s - loss: 1.8776 - mean_absolute_error: 0.7127\n",
      " Temp MAE = 0.267, Hum MAE = 1.194    \n",
      "9200/9200 [==============================] - 8s 879us/step - loss: 1.8797 - mean_absolute_error: 0.7135 - val_loss: 1.9067 - val_mean_absolute_error: 0.7304\n",
      "Epoch 19/50\n",
      "9175/9200 [============================>.] - ETA: 0s - loss: 1.8757 - mean_absolute_error: 0.7130- ETA: 0s - loss: 1.8597 - mean_absolute_error: 0.7\n",
      " Temp MAE = 0.279, Hum MAE = 1.225    \n",
      "9200/9200 [==============================] - 9s 950us/step - loss: 1.8790 - mean_absolute_error: 0.7137 - val_loss: 1.9333 - val_mean_absolute_error: 0.7518\n",
      "Epoch 20/50\n",
      "9161/9200 [============================>.] - ETA: 0s - loss: 1.8771 - mean_absolute_error: 0.7134\n",
      " Temp MAE = 0.240, Hum MAE = 1.096    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 9s 960us/step - loss: 1.8812 - mean_absolute_error: 0.7138 - val_loss: 1.8271 - val_mean_absolute_error: 0.6679\n",
      "Epoch 21/50\n",
      "9196/9200 [============================>.] - ETA: 0s - loss: 1.8727 - mean_absolute_error: 0.7111- ETA: 1s - loss: 1.8711 - mean_ab\n",
      " Temp MAE = 0.268, Hum MAE = 1.114    \n",
      "9200/9200 [==============================] - 8s 846us/step - loss: 1.8736 - mean_absolute_error: 0.7113 - val_loss: 1.8345 - val_mean_absolute_error: 0.6911\n",
      "Epoch 22/50\n",
      "9170/9200 [============================>.] - ETA: 0s - loss: 1.8790 - mean_absolute_error: 0.7118\n",
      " Temp MAE = 0.237, Hum MAE = 1.092    \n",
      "9200/9200 [==============================] - 8s 910us/step - loss: 1.8790 - mean_absolute_error: 0.7120 - val_loss: 1.8361 - val_mean_absolute_error: 0.6644\n",
      "Epoch 23/50\n",
      "9122/9200 [============================>.] - ETA: 0s - loss: 1.8701 - mean_absolute_error: 0.7098- ETA: 2s - loss: 1.8721  - ETA: 1s - loss: 1.8621 - mean_\n",
      " Temp MAE = 0.266, Hum MAE = 1.248    \n",
      "9200/9200 [==============================] - 9s 932us/step - loss: 1.8742 - mean_absolute_error: 0.7108 - val_loss: 1.9804 - val_mean_absolute_error: 0.7574\n",
      "Epoch 24/50\n",
      "9187/9200 [============================>.] - ETA: 0s - loss: 1.8794 - mean_absolute_error: 0.7129\n",
      " Temp MAE = 0.262, Hum MAE = 1.241    \n",
      "9200/9200 [==============================] - 8s 873us/step - loss: 1.8803 - mean_absolute_error: 0.7131 - val_loss: 1.9341 - val_mean_absolute_error: 0.7515\n",
      "Epoch 25/50\n",
      "9167/9200 [============================>.] - ETA: 0s - loss: 1.8755 - mean_absolute_error: 0.7116- ETA: 1s - loss: 1.8740 - mean_\n",
      " Temp MAE = 0.238, Hum MAE = 1.110    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 10s 1ms/step - loss: 1.8764 - mean_absolute_error: 0.7120 - val_loss: 1.8268 - val_mean_absolute_error: 0.6738\n",
      "Epoch 26/50\n",
      "9160/9200 [============================>.] - ETA: 0s - loss: 1.8753 - mean_absolute_error: 0.7109- ET\n",
      " Temp MAE = 0.262, Hum MAE = 1.149    \n",
      "9200/9200 [==============================] - 9s 928us/step - loss: 1.8763 - mean_absolute_error: 0.7114 - val_loss: 1.8479 - val_mean_absolute_error: 0.7057\n",
      "Epoch 27/50\n",
      "9177/9200 [============================>.] - ETA: 0s - loss: 1.8735 - mean_absolute_error: 0.7104\n",
      " Temp MAE = 0.255, Hum MAE = 1.161    \n",
      "9200/9200 [==============================] - 9s 932us/step - loss: 1.8743 - mean_absolute_error: 0.7106 - val_loss: 1.8687 - val_mean_absolute_error: 0.7080\n",
      "Epoch 28/50\n",
      "9166/9200 [============================>.] - ETA: 0s - loss: 1.8674 - mean_absolute_error: 0.7089- ETA: 2s - loss: 1.9171 - ETA: 0s - loss: 1.8294 - mean_absolute_ - ETA: 0s - loss: 1.8703 - mean_absolute_error: 0.7097\n",
      " Temp MAE = 0.256, Hum MAE = 1.167    \n",
      "9200/9200 [==============================] - 9s 927us/step - loss: 1.8725 - mean_absolute_error: 0.7102 - val_loss: 1.8690 - val_mean_absolute_error: 0.7116\n",
      "Epoch 29/50\n",
      "9157/9200 [============================>.] - ETA: 0s - loss: 1.8713 - mean_absolute_error: 0.7097- ETA: 6s - loss: 1.5736 - mean_absolute_err - ETA: 6s - loss: 2.2668 - mean_absolute_ - ETA: 5s - loss: 1.8170 - mean_absolute_error: 0.6 - ETA: 5s - loss: 1.8 - ETA: 3 - ETA: 1s - loss: 1.8359 - - ETA: 0s - loss: 1.8412 - mean_absolute_error: 0\n",
      " Temp MAE = 0.279, Hum MAE = 1.185    \n",
      "9200/9200 [==============================] - 9s 940us/step - loss: 1.8732 - mean_absolute_error: 0.7102 - val_loss: 1.9044 - val_mean_absolute_error: 0.7318\n",
      "Epoch 30/50\n",
      "9159/9200 [============================>.] - ETA: 0s - loss: 1.8679 - mean_absolute_error: 0.7093\n",
      " Temp MAE = 0.277, Hum MAE = 1.112    \n",
      "9200/9200 [==============================] - 9s 928us/step - loss: 1.8732 - mean_absolute_error: 0.7105 - val_loss: 1.8419 - val_mean_absolute_error: 0.6944\n",
      "Epoch 31/50\n",
      "9139/9200 [============================>.] - ETA: 0s - loss: 1.8718 - mean_absolute_error: 0.7094- ETA: 2s - loss: 1.9234 - mean_absolute_err - ETA: 1s - loss: 1.8487 - mean_absolute_error: 0.703 - ETA: 1s - loss: 1.8421 - mean_absolute_error:  - ETA: 1s - loss: 1.8408 -\n",
      " Temp MAE = 0.243, Hum MAE = 1.142    \n",
      "9200/9200 [==============================] - 8s 917us/step - loss: 1.8748 - mean_absolute_error: 0.7103 - val_loss: 1.8851 - val_mean_absolute_error: 0.6926\n",
      "Epoch 32/50\n",
      "9166/9200 [============================>.] - ETA: 0s - loss: 1.8689 - mean_absolute_error: 0.7083\n",
      " Temp MAE = 0.254, Hum MAE = 1.100    \n",
      "9200/9200 [==============================] - 9s 943us/step - loss: 1.8717 - mean_absolute_error: 0.7090 - val_loss: 1.8288 - val_mean_absolute_error: 0.6771\n",
      "Epoch 33/50\n",
      "9170/9200 [============================>.] - ETA: 0s - loss: 1.8738 - mean_absolute_error: 0.7098\n",
      " Temp MAE = 0.248, Hum MAE = 1.109    \n",
      "9200/9200 [==============================] - 9s 1ms/step - loss: 1.8739 - mean_absolute_error: 0.7100 - val_loss: 1.8270 - val_mean_absolute_error: 0.6788\n",
      "Epoch 34/50\n",
      "9169/9200 [============================>.] - ETA: 0s - loss: 1.8696 - mean_absolute_error: 0.7080\n",
      " Temp MAE = 0.235, Hum MAE = 1.108    \n",
      "9200/9200 [==============================] - 8s 843us/step - loss: 1.8712 - mean_absolute_error: 0.7085 - val_loss: 1.8362 - val_mean_absolute_error: 0.6715\n",
      "Epoch 35/50\n",
      "9182/9200 [============================>.] - ETA: 0s - loss: 1.8695 - mean_absolute_error: 0.7080\n",
      " Temp MAE = 0.249, Hum MAE = 1.144    \n",
      "9200/9200 [==============================] - 8s 893us/step - loss: 1.8699 - mean_absolute_error: 0.7083 - val_loss: 1.9139 - val_mean_absolute_error: 0.6961\n",
      "Epoch 36/50\n",
      "9169/9200 [============================>.] - ETA: 0s - loss: 1.8702 - mean_absolute_error: 0.7088- ETA: 1s - loss: 1\n",
      " Temp MAE = 0.242, Hum MAE = 1.105    \n",
      "INFO:tensorflow:Assets written to: ./callback_mlp_V( a_alpha=0.03 )_chkp\\mlp_V( a_alpha=0.03 )_chkp_best\\assets\n",
      "9200/9200 [==============================] - 10s 1ms/step - loss: 1.8715 - mean_absolute_error: 0.7092 - val_loss: 1.8186 - val_mean_absolute_error: 0.6734\n",
      "Epoch 37/50\n",
      "9187/9200 [============================>.] - ETA: 0s - loss: 1.8705 - mean_absolute_error: 0.7084- ETA: 1s - loss: 1.8515 - mea\n",
      " Temp MAE = 0.249, Hum MAE = 1.168    \n",
      "9200/9200 [==============================] - 8s 903us/step - loss: 1.8703 - mean_absolute_error: 0.7085 - val_loss: 1.8735 - val_mean_absolute_error: 0.7083\n",
      "Epoch 38/50\n",
      "9171/9200 [============================>.] - ETA: 0s - loss: 1.8660 - mean_absolute_error: 0.7073\n",
      " Temp MAE = 0.248, Hum MAE = 1.110    \n",
      "9200/9200 [==============================] - 10s 1ms/step - loss: 1.8682 - mean_absolute_error: 0.7078 - val_loss: 1.8318 - val_mean_absolute_error: 0.6793\n",
      "Epoch 39/50\n",
      "9171/9200 [============================>.] - ETA: 0s - loss: 1.8662 - mean_absolute_error: 0.7075\n",
      " Temp MAE = 0.243, Hum MAE = 1.164    \n",
      "9200/9200 [==============================] - 10s 1ms/step - loss: 1.8700 - mean_absolute_error: 0.7083 - val_loss: 1.8861 - val_mean_absolute_error: 0.7034\n",
      "Epoch 40/50\n",
      "9164/9200 [============================>.] - ETA: 0s - loss: 1.8666 - mean_absolute_error: 0.7066\n",
      " Temp MAE = 0.254, Hum MAE = 1.142    \n",
      "9200/9200 [==============================] - 10s 1ms/step - loss: 1.8676 - mean_absolute_error: 0.7071 - val_loss: 1.8485 - val_mean_absolute_error: 0.6983\n",
      "Epoch 41/50\n",
      "9181/9200 [============================>.] - ETA: 0s - loss: 1.8674 - mean_absolute_error: 0.7083\n",
      " Temp MAE = 0.261, Hum MAE = 1.104    \n",
      "9200/9200 [==============================] - 9s 1ms/step - loss: 1.8705 - mean_absolute_error: 0.7090 - val_loss: 1.8301 - val_mean_absolute_error: 0.6826\n",
      "Epoch 42/50\n",
      "9113/9200 [============================>.] - ETA: 0s - loss: 1.8644 - mean_absolute_error: 0.7063\n",
      " Temp MAE = 0.259, Hum MAE = 1.106    \n",
      "9200/9200 [==============================] - 8s 877us/step - loss: 1.8704 - mean_absolute_error: 0.7079 - val_loss: 1.8288 - val_mean_absolute_error: 0.6824\n",
      "Epoch 43/50\n",
      "9177/9200 [============================>.] - ETA: 0s - loss: 1.8652 - mean_absolute_error: 0.7064\n",
      " Temp MAE = 0.288, Hum MAE = 1.247    \n",
      "9200/9200 [==============================] - 8s 917us/step - loss: 1.8669 - mean_absolute_error: 0.7069 - val_loss: 1.9450 - val_mean_absolute_error: 0.7672\n",
      "Epoch 44/50\n",
      "9150/9200 [============================>.] - ETA: 0s - loss: 1.8651 - mean_absolute_error: 0.7065\n",
      " Temp MAE = 0.271, Hum MAE = 1.112    \n",
      "9200/9200 [==============================] - 8s 880us/step - loss: 1.8670 - mean_absolute_error: 0.7072 - val_loss: 1.8428 - val_mean_absolute_error: 0.6919\n",
      "Epoch 45/50\n",
      "9195/9200 [============================>.] - ETA: 0s - loss: 1.8672 - mean_absolute_error: 0.7069\n",
      " Temp MAE = 0.239, Hum MAE = 1.130    \n",
      "9200/9200 [==============================] - 9s 926us/step - loss: 1.8675 - mean_absolute_error: 0.7070 - val_loss: 1.8901 - val_mean_absolute_error: 0.6849\n",
      "Epoch 46/50\n",
      "9158/9200 [============================>.] - ETA: 0s - loss: 1.8619 - mean_absolute_error: 0.7064\n",
      " Temp MAE = 0.236, Hum MAE = 1.152    \n",
      "9200/9200 [==============================] - 9s 960us/step - loss: 1.8673 - mean_absolute_error: 0.7070 - val_loss: 1.9163 - val_mean_absolute_error: 0.6940\n",
      "Epoch 47/50\n",
      "9167/9200 [============================>.] - ETA: 0s - loss: 1.8693 - mean_absolute_error: 0.7075\n",
      " Temp MAE = 0.232, Hum MAE = 1.114    \n",
      "9200/9200 [==============================] - 9s 959us/step - loss: 1.8702 - mean_absolute_error: 0.7077 - val_loss: 1.8588 - val_mean_absolute_error: 0.6728\n",
      "Epoch 48/50\n",
      "9132/9200 [============================>.] - ETA: 0s - loss: 1.8591 - mean_absolute_error: 0.7049\n",
      " Temp MAE = 0.260, Hum MAE = 1.196    \n",
      "9200/9200 [==============================] - 8s 878us/step - loss: 1.8665 - mean_absolute_error: 0.7065 - val_loss: 1.8914 - val_mean_absolute_error: 0.7280\n",
      "Epoch 49/50\n",
      "9187/9200 [============================>.] - ETA: 0s - loss: 1.8664 - mean_absolute_error: 0.7074\n",
      " Temp MAE = 0.252, Hum MAE = 1.095    \n",
      "9200/9200 [==============================] - 8s 872us/step - loss: 1.8672 - mean_absolute_error: 0.7075 - val_loss: 1.8424 - val_mean_absolute_error: 0.6737\n",
      "Epoch 50/50\n",
      "9170/9200 [============================>.] - ETA: 0s - loss: 1.8629 - mean_absolute_error: 0.7055\n",
      " Temp MAE = 0.298, Hum MAE = 1.164    \n",
      "9200/9200 [==============================] - 8s 851us/step - loss: 1.8631 - mean_absolute_error: 0.7058 - val_loss: 1.8866 - val_mean_absolute_error: 0.7311\n"
     ]
    }
   ],
   "source": [
    "if Structured == True :\n",
    "    model = get_model(mymodel)\n",
    "    history = model.fit(train_ds, epochs=50,   validation_data=val_ds,callbacks=[mycallback ,cp_callback ])\n",
    "if Structured == False :\n",
    "# Create  Unstructiured Pruning Callback  to to apply pruning during Training and fitting the model\n",
    "    model = MODELS[mymodel]\n",
    "    # Define the sparsity scheduler\n",
    "    pruning_params = {'pruning_schedule':\n",
    "    tfmot.sparsity.keras.PolynomialDecay(\n",
    "    initial_sparsity=0.30,\n",
    "    final_sparsity=sparsity,\n",
    "    begin_step=len(train_ds)*5,\n",
    "    end_step=len(train_ds)*15)\n",
    "    }\n",
    "\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "    model = prune_low_magnitude(model, **pruning_params)\n",
    "    # Define the pruning callback\n",
    "    PruningCallback = [tfmot.sparsity.keras.UpdatePruningStep()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378e367-0524-432d-884e-462f68506e30",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Trianing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54f8b813-4f04-45e6-82bf-60cea919d365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Flatten (Flatten)            (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 3)                 39        \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "Output_layes (Dense)         (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 3, 2)              0         \n",
      "=================================================================\n",
      "Total params: 75\n",
      "Trainable params: 75\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if Structured == False :\n",
    "    loss =   tf.keras.losses.MeanSquaredError()                       \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    metrics = [MultiOutputMAE()]\n",
    "    input_shape = [32, 6, 2]\n",
    "    model.build(input_shape)\n",
    "    model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
    "    history = model.fit(train_ds, epochs=50,   validation_data=val_ds,callbacks=[ PruningCallback])\n",
    "\n",
    "    model_to_export = tfmot.sparsity.keras.strip_pruning(model)\n",
    "\n",
    "    \n",
    "############################## Print Model Summary ####################\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93762cc8-06f7-4029-9081-3e31a198233c",
   "metadata": {},
   "source": [
    "# print the training results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "917fddf2-35b8-4c09-bb07-12114e8d7e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(mymodel+\".png\")\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f97423-df8d-4ad9-8cfa-5e54a922dc23",
   "metadata": {},
   "source": [
    "# Evaluation Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a18549d-52fb-4f21-8e93-fe9909cef292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pruned_Model_evaluate_and_compress_to_TFlite(model = model , model_to_export=None,tflite_model_dir =  TFLITE , model_name = mymodel  ):\n",
    "    \n",
    "    if not os.path.exists('./Pruned_models'):\n",
    "        os.makedirs('./Pruned_models')\n",
    "    # Model Evaluation\n",
    "    loss, error = model.evaluate(test_ds)\n",
    "    print(f'Temp mae = {error[0]:.3f}: , HUM mae = {error[1]:.3f} ')  \n",
    "    # Convert to TF lite without Quantization \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()  \n",
    "    # Write the model in binary formate and save it \n",
    "    with open(tflite_model_dir, 'wb') as fp:\n",
    "        fp.write(tflite_model)\n",
    "    Compressed =  f\"compressed_{TFLITE}\"\n",
    "    with open(Compressed, 'wb') as fp:\n",
    "        tflite_compressed = zlib.compress(tflite_model)\n",
    "        fp.write(tflite_compressed)\n",
    "    print(f\"the model is saved successfuly to {tflite_model_dir}\")\n",
    "    return Compressed , tflite_model_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3311768-d3fa-49db-bbb0-31084ee1829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_Quantization(tflite_model_dir =  TFLITE ,  PQT = False , WAPQT = False , Structured = Structured , saving_path = None ): \n",
    "    if Structured == False :\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    if Structured == True :\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(saving_path)\n",
    "    # Apply weight only quantization \n",
    "    if PQT == True :\n",
    "        tflite_model_dir = f\"PQT_{tflite_model_dir}\"\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "    # Apply weight + Activation  quantization \n",
    "    if WAPQT == True :\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_dataset_gen\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        tflite_model_dir = f\"WAPQT_{tflite_model_dir}\"\n",
    "      \n",
    "    # Write the model in binary formate and save it \n",
    "    with open(tflite_model_dir, 'wb') as fp:\n",
    "        fp.write(tflite_model)\n",
    "    Compressed =  f\"compressed_{tflite_model_dir}\"\n",
    "    with open(Compressed, 'wb') as fp:\n",
    "        tflite_compressed = zlib.compress(tflite_model)\n",
    "        fp.write(tflite_compressed)\n",
    "    print(f\"the model is saved successfuly to {tflite_model_dir}\")\n",
    "    return Compressed , tflite_model_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4be46230-65a6-43ba-a951-60d3c3d94e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for weight and activations quantization \n",
    "def representative_dataset_gen():\n",
    "    for x, _ in train_ds.take(1000):\n",
    "        yield [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73617dec-ae71-491e-a495-7ab67e3b56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_pruning_Model_evaluate_and_compress_to_TFlite( tflite_model_dir =  TFLITE , chk_path = chk_path , model_name = mymodel , PQT = False , WAPQT = False , Structured = Structured):\n",
    "    if not os.path.exists('./models'):\n",
    "        os.makedirs('./models')\n",
    "    model = tf.keras.models.load_model(filepath = chk_path , custom_objects={'MultiOutputMAE':MultiOutputMAE})\n",
    "\n",
    "    run_model = tf.function(lambda x: model(x))\n",
    "    # input_shape = model.inputs[0].shape.as_list()\n",
    "    # input_shape[0] = batch_size\n",
    "    # func = tf.function(model).get_concrete_function(\n",
    "    # tf.TensorSpec(input_shape, model.inputs[0].dtype))\n",
    "    concrete_func = run_model.get_concrete_function(tf.TensorSpec([1, 6, 2], tf.float32))\n",
    "    saving_path = os.path.join('.','models', model_name)\n",
    "    model.save(saving_path ,signatures=concrete_func )\n",
    "\n",
    "    best_model = tf.keras.models.load_model(filepath = saving_path , custom_objects={'MultiOutputMAE':MultiOutputMAE})\n",
    "    loss, error = best_model.evaluate(test_ds)\n",
    "    print(f'Temp mae = {error[0]:.3f}: , HUM mae = {error[1]:.3f} ')\n",
    "    # Convert to TF lite without Quantization \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()  \n",
    "\n",
    "    # Write the model in binary formate and save it \n",
    "    with open(tflite_model_dir, 'wb') as fp:\n",
    "        fp.write(tflite_model)\n",
    "    Compressed = \"compressed_\"+tflite_model_dir \n",
    "    with open(Compressed, 'wb') as fp:\n",
    "        tflite_compressed = zlib.compress(tflite_model)\n",
    "        fp.write(tflite_compressed)\n",
    "    print(f\"the model is saved successfuly to {tflite_model_dir}\")\n",
    "    return Compressed , tflite_model_dir , saving_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab53d6e3-2dda-41cc-b5a7-ab26d8c55d75",
   "metadata": {},
   "source": [
    "# load_and_evaluation of TF lite model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d4db77-169e-4e1f-9947-c41ada35c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_evaluation(path, dataset):\n",
    "    interpreter = tf.lite.Interpreter(model_path = path) \n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    dataset = test_ds.unbatch().batch(1)\n",
    "\n",
    "    outputs = []\n",
    "    labels = []\n",
    "    print(dataset)\n",
    "\n",
    "    for data in dataset:\n",
    "        my_input = np.array(data[0], dtype = np.float32)\n",
    "        label = np.array(data[1], dtype = np.float32)\n",
    "        # print (f\"my_input = {my_input}\")\n",
    "        # print(f\"label = {label}\")\n",
    "\n",
    "    \n",
    "            \n",
    "        labels.append(label)\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], my_input)\n",
    "        interpreter.invoke()\n",
    "        my_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        outputs.append(my_output[0])\n",
    "\n",
    "    outputs = np.squeeze( np.array(outputs))\n",
    "    labels = np.squeeze(np.array(labels))\n",
    "\n",
    "    \n",
    "    error = np.absolute(outputs - labels)\n",
    "  \n",
    "    mean_axis_1 = np.mean(error , axis = 1)     #  ==>  np.sum(error, axis = 1)/labels.shape[1]\n",
    "    \n",
    "    mae = np.mean(mean_axis_1 , axis = 0)  #  ==> np.sum(mean_axis_1, axis = 0) /mean_axis_1.shape[0]\n",
    "    temp_MAE = mae[0] \n",
    "    hum_MAE = mae[1]\n",
    "    print(\"*\"*50,\"\\n\",f\" Excuting the model {path} \")\n",
    "    print(\"*\"*50,\"\\n\",f\" mae is {mae} of shape {mae.shape} \")\n",
    "    print(\"*\"*50,\"\\n\",f'Temp mae = {mae[0]:.3f}: , HUM mae = {mae[1]:.3f} ')\n",
    "    \n",
    "    # check version \"a\" requirment\n",
    "    if version == \"a\" :\n",
    "        if temp_MAE <= 0.3 and hum_MAE <= 1.2 :\n",
    "            print (\"*\"*50,\"\\n\",\"achieved the requirments \" )\n",
    "        else :\n",
    "            print (\"*\"*50,\"\\n\",\"Not achieved the requirments\" )\n",
    "    # check version \"b\" requirment        \n",
    "    if version == \"b\" :\n",
    "        if temp_MAE <= 0.7 and hum_MAE <= 2.5 :\n",
    "            print (\"*\"*50,\"\\n\",\"achieved the requirments \" )\n",
    "        else :\n",
    "            print (\"*\"*50,\"\\n\",\"Not achieved the requirments\" ) \n",
    "\n",
    "#     return mae \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ec949-94cf-4ce3-a393-395fe8072468",
   "metadata": {},
   "source": [
    "# get the size of tf_lite model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2daddeb-9bda-4f53-8239-f2761035d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsize(file):\n",
    "    st = os.stat(file)\n",
    "    size = st.st_size\n",
    "    return size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d5f4c-dc32-4b77-940b-8cf2a23c4625",
   "metadata": {},
   "source": [
    "### Without Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42b077dc-6ec5-46f8-83ad-80f2b9235d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\models\\mlp_V( a_alpha=0.03 )\\assets\n",
      "1314/1314 [==============================] - 2s 2ms/step - loss: 1.9492 - mean_absolute_error: 0.7225\n",
      "Temp mae = 0.259: , HUM mae = 1.186 \n",
      "INFO:tensorflow:Assets written to: C:\\Users\\musta\\AppData\\Local\\Temp\\tmp3hef7ib8\\assets\n",
      "the model is saved successfuly to mlp_V( a_alpha=0.03 ).tflite\n",
      " \n",
      " Size of TF.lite model is 3.128 KB\n",
      " \n",
      " Size of compressed_tflite model is 1.454 KB\n",
      "mlp_V( a_alpha=0.03 ).tflite\n"
     ]
    }
   ],
   "source": [
    "if Structured == False :\n",
    "    tflite_model_dir_Compressed ,tf_lite_model_path = Pruned_Model_evaluate_and_compress_to_TFlite(model_to_export=model_to_export)\n",
    "if Structured == True :\n",
    "    tflite_model_dir_Compressed ,tf_lite_model_path, saving_path  = S_pruning_Model_evaluate_and_compress_to_TFlite(TFLITE)\n",
    "# print(b)\n",
    "tflite_size = getsize(tf_lite_model_path)\n",
    "compressed_tflite_size = getsize(tflite_model_dir_Compressed )\n",
    "print(f\" \\n Size of TF.lite model is {tflite_size /1000} KB\")\n",
    "print(f\" \\n Size of compressed_tflite model is {compressed_tflite_size /1000} KB\")\n",
    "print(tf_lite_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a006e396-b68d-4369-846a-171b71853b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 6, 2), (None, 3, 2)), types: (tf.float32, tf.float32)>\n",
      "************************************************** \n",
      "  Excuting the model mlp_V( a_alpha=0.03 ).tflite \n",
      "************************************************** \n",
      "  mae is [0.258553  1.1863916] of shape (2,) \n",
      "************************************************** \n",
      " Temp mae = 0.259: , HUM mae = 1.186 \n",
      "************************************************** \n",
      " achieved the requirments \n"
     ]
    }
   ],
   "source": [
    "load_and_evaluation(tf_lite_model_path , test_ds) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693f0192-e2be-4650-9d8f-0f4ffa78a661",
   "metadata": {},
   "source": [
    "### Weights only Quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae31c5a4-b8db-46e0-9a55-fcd879217924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model is saved successfuly to PQT_mlp_V( a_alpha=0.03 ).tflite\n",
      " \n",
      " Size of TF.lite model is 4.08 KB\n",
      " \n",
      " Size of compressed_tflite model is 1.529 KB\n"
     ]
    }
   ],
   "source": [
    "if Structured == False :\n",
    "    tflite_model_dir_Compressed ,tf_lite_model_path = apply_Quantization( PQT=True)\n",
    "if Structured == True :\n",
    "    Compressed , Quantized   = apply_Quantization(PQT=True ,  saving_path=chk_path)\n",
    "# print(b)\n",
    "tflite_size = getsize(Quantized)\n",
    "compressed_tflite_size = getsize(Compressed )\n",
    "print(f\" \\n Size of TF.lite model is {tflite_size /1000} KB\")\n",
    "print(f\" \\n Size of compressed_tflite model is {compressed_tflite_size /1000} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f3003aa-e255-4aec-895c-81a55b443518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 6, 2), (None, 3, 2)), types: (tf.float32, tf.float32)>\n",
      "************************************************** \n",
      "  Excuting the model PQT_mlp_V( a_alpha=0.03 ).tflite \n",
      "************************************************** \n",
      "  mae is [0.258553  1.1863916] of shape (2,) \n",
      "************************************************** \n",
      " Temp mae = 0.259: , HUM mae = 1.186 \n",
      "************************************************** \n",
      " achieved the requirments \n"
     ]
    }
   ],
   "source": [
    "load_and_evaluation(Quantized , test_ds) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191d4b6-d449-465a-adc5-b4367a60027f",
   "metadata": {},
   "source": [
    "###  Weights + activations  Quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1b23043-2634-4a5c-af7e-937d374ca918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model is saved successfuly to WAPQT_mlp_V( a_alpha=0.03 ).tflite\n",
      " \n",
      " Size of TF.lite model is 4.816 KB\n",
      " \n",
      " Size of compressed_tflite model is 1.598 KB\n"
     ]
    }
   ],
   "source": [
    "if Structured == False :\n",
    "    tflite_model_dir_Compressed ,tf_lite_model_path = apply_Quantization( WAPQT=True)\n",
    "if Structured == True :\n",
    "    Compressed , Quantized   = apply_Quantization(WAPQT=True , saving_path=chk_path)\n",
    "# print(b)\n",
    "tflite_size = getsize(Quantized)\n",
    "compressed_tflite_size = getsize(Compressed )\n",
    "print(f\" \\n Size of TF.lite model is {tflite_size /1000} KB\")\n",
    "print(f\" \\n Size of compressed_tflite model is {compressed_tflite_size /1000} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0251fb8c-7814-4052-8256-0c71406e9274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 6, 2), (None, 3, 2)), types: (tf.float32, tf.float32)>\n",
      "************************************************** \n",
      "  Excuting the model WAPQT_mlp_V( a_alpha=0.03 ).tflite \n",
      "************************************************** \n",
      "  mae is [0.38221422 1.216565  ] of shape (2,) \n",
      "************************************************** \n",
      " Temp mae = 0.382: , HUM mae = 1.217 \n",
      "************************************************** \n",
      " Not achieved the requirments\n"
     ]
    }
   ],
   "source": [
    "load_and_evaluation(Quantized , test_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af99f9-2046-4156-92e5-3890e783f925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
